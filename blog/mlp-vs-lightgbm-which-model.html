<!DOCTYPE html>
<html lang="en">
<head>
	<title>MLP Vs LightGBM: Which Model Wins For Classification?</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="MLP Vs LightGBM: Which Model Wins For Classification?...">
    <link rel="canonical" href="https://catatansoal.github.io/blog/mlp-vs-lightgbm-which-model">
	<meta property="og:type" content="article">
	<meta property="og:title" content="MLP Vs LightGBM: Which Model Wins For Classification?">
	<meta property="og:description" content="MLP Vs LightGBM: Which Model Wins For Classification?...">
	<meta property="og:url" content="https://catatansoal.github.io/blog/mlp-vs-lightgbm-which-model">
	<meta property="og:site_name" content="Question Notes">
	<meta property="article:published_time" content="2025-08-12T14:42:46+00:00">
	<meta property="article:author" content="ADMIN">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    <link rel="preload" as="script" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js">
    <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
    <link rel="preload" fetchpriority="high" as="image" href="https://tse4.mm.bing.net/th?q=MLP%20vs%20LightGBM%3A%20A%20Deep%20Dive%20Comparison">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <style type="text/css">
    	:root{--primary-color:#3740ff;--text-color:#202124;--background-color:#ffffff;--gray-100:#f8f9fa;--gray-200:#e9ecef}*{margin:0;padding:0;box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;line-height:1.6;color:var(--text-color);background-color:var(--background-color)}.container{max-width:1200px;margin:0 auto;padding:0 1.5rem}.header{background-color:var(--background-color);border-bottom:1px solid var(--gray-200);position:sticky;top:0;z-index:100}.nav{padding:.5rem 0}.nav-container{display:flex;justify-content:space-between;align-items:center;gap:1rem}.nav-left{display:flex;align-items:center;flex-shrink:0}.logo{font-weight:700;color:var(--primary-color)}.blog-tag{margin-left:1rem;padding:.25rem .5rem;background-color:var(--gray-100);border-radius:4px;font-size:.875rem}.nav-search{flex-grow:1;max-width:300px}.search-form{position:relative;width:100%}.search-input{width:100%;padding:.5rem 2.5rem .5rem 1rem;border:1px solid var(--gray-200);border-radius:24px;font-size:.875rem;transition:all 0.2s}.search-input:focus{outline:none;border-color:var(--primary-color);box-shadow:0 0 0 2px rgb(55 64 255 / .1)}.search-button{position:absolute;right:.5rem;top:50%;transform:translateY(-50%);background:none;border:none;color:#5f6368;cursor:pointer;padding:.25rem;display:flex;align-items:center;justify-content:center}.search-button:hover{color:var(--primary-color)}.nav-toggle{display:none;background:none;border:none;cursor:pointer;padding:.5rem}.hamburger{display:block;position:relative;width:24px;height:2px;background:var(--text-color);transition:all 0.3s}.hamburger::before,.hamburger::after{content:'';position:absolute;width:24px;height:2px;background:var(--text-color);transition:all 0.3s}.hamburger::before{top:-6px}.hamburger::after{bottom:-6px}.nav-toggle-active .hamburger{background:#fff0}.nav-toggle-active .hamburger::before{transform:rotate(45deg);top:0}.nav-toggle-active .hamburger::after{transform:rotate(-45deg);bottom:0}.nav-list{display:flex;list-style:none;gap:2rem}.nav-link{color:var(--text-color);text-decoration:none;font-size:.9rem;transition:color 0.2s}.nav-link:hover{color:var(--primary-color)}.article-header{padding:2rem 0;background-color:var(--gray-100)}.article-layout{display:grid;grid-template-columns:1fr 350px;gap:3rem;padding:1rem 0;align-items: start}h1,h2,h3,h4,h5,h6{font-family:"Crimson Text","Times New Roman",Times,serif}h1{font-size:2.5rem;line-height:1.2;margin-bottom:1rem}.meta{color:#5f6368;font-size:.875rem;display:flex;align-items:center;gap:1rem;flex-wrap:wrap}.view-count{display:inline-flex;align-items:center;gap:.25rem}.view-count svg{color:#5f6368}.content{min-width:0;border-bottom:1px solid #dddddd5e;margin-top:1rem;white-space:pre-line !important;overflow-wrap:break-word;overflow-x:auto;word-break:break-word}.lead{font-size:1.25rem;color:#5f6368;margin-bottom:2rem}h2,h3,h4,h5,h6{font-size:1.75rem;margin:1rem 0 1rem}p,pre,ol,ul>li{margin-bottom:1rem;font-family:"Newsreader",serif;font-optical-sizing:auto;font-style:normal;font-size:1.3rem;text-align: justify;}p>code{font-size:1rem;font-weight:700;padding:.1rem .3rem .1rem .3rem;background:#0000000f;color:#000;border-radius:5px}hr{margin:1rem 0 1rem 0}.code-example{background-color:var(--gray-100);padding:1.5rem;border-radius:8px;margin:1.5rem 0;overflow-x:auto}code{font-family:'Roboto Mono',monospace;font-size:.875rem}ul{margin:.2rem 0;padding-left:1.5rem}.related-posts{background-color:var(--gray-100);padding:1.5rem;border-radius:8px;position:sticky;top:5rem}.related-posts-title,.newpost-posts-list{font-size:1.75rem;margin:0 0 1rem}.related-posts-list{display:flex;flex-direction:column;gap:.5rem}.related-post,.newpost-post{border-bottom:1px solid #ddd;padding-bottom:10px;margin-bottom:10px}.related-post:last-child,.newpost-post:last-child{padding-bottom:0;border-bottom:none}.related-post-title,.newpost-post-title{font-size:1.2rem;margin:0 0 .1rem;font-family:"Newsreader",serif;font-optical-sizing:auto;font-style:normal;display: -webkit-box;-webkit-line-clamp: 3;-webkit-box-orient: vertical;overflow: hidden;}.related-post-title a,.newpost-post-title a{color:var(--text-color);text-decoration:none;transition:color 0.2s}.related-post-title a:hover,.newpost-post-title a:hover{color:var(--primary-color)}.related-post time{font-size:.875rem;color:#5f6368}.footer{background-color:var(--gray-100);padding:2rem 0;margin-top:4rem;color:#5f6368;font-size:.875rem}.nav-menu>ul>li{margin-bottom:0}@media (max-width:1024px){.container{max-width:800px}.article-layout{grid-template-columns:1fr;gap:2rem}.related-posts{position:static}}@media (max-width:768px){.nav-container{flex-wrap:wrap}.nav-search{order:3;max-width:none;width:100%;margin-top:.1rem}.nav-toggle{display:block}.nav-menu{display:none;position:absolute;top:100%;left:0;right:0;background:var(--background-color);padding:1rem 0;border-bottom:1px solid var(--gray-200)}.nav-menu-active{display:block}.nav-list{flex-direction:column;gap:.1rem;padding:0 1.5rem}.nav-link{display:block;padding:.2rem 0}h1{font-size:2rem}.article-header{padding:2rem 0}.content{padding:.1rem 0}}table{width:100%;border-collapse:collapse;margin:20px 0;font-family:'Arial',sans-serif}th,td{padding:12px 15px;text-align:left;border:1px solid #ddd}th{background-color:#0F7F0B;color:#FFF}td{background-color:#f9f9f9}tr:nth-child(even) td{background-color:#f2f2f2}@media screen and (max-width:768px){table{border:0;display:block;overflow-x:auto;white-space:nowrap}th,td{padding:10px;text-align:right}th{background-color:#0F7F0B;color:#FFF}td{background-color:#f9f9f9;border-bottom:1px solid #ddd}tr:nth-child(even) td{background-color:#f2f2f2}}a{text-decoration:none;color:#540707}.katex-html{padding: .2rem;color: #000;font-weight: 700;font-size: 1.3rem;overflow-wrap: break-word;max-width: 100%;white-space: normal !important}.category{display:flex;align-items:center;gap:.5rem;flex-wrap:wrap;margin:1rem 0 1rem 0}.tag{font-size:1rem;font-weight:700;padding:.1rem .3rem .1rem .3rem;background:#0000000f;color:#000;border-radius:5px;font-family:"Newsreader",serif}.tag>a{text-decoration:none;color:#000}img{margin:auto;display:block;max-width:100%;height:auto;margin-bottom:1rem}.katex{white-space: pre-line !important;display: inline-block;max-width: 100%;overflow-x: auto;overflow-y: hidden;scrollbar-width: thin;overflow-wrap: break-word;word-break: break-word;vertical-align: -7px}.content > p {overflow-wrap: break-word;word-break: break-word}
    </style>
    <style type="text/css">
    	pre code.hljs{display:block;overflow-x:auto;padding:1em}code.hljs{padding:3px 5px}
		.hljs{color:#c9d1d9;background:#0d1117}.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#ff7b72}.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#d2a8ff}.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#79c0ff}.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#a5d6ff}.hljs-built_in,.hljs-symbol{color:#ffa657}.hljs-code,.hljs-comment,.hljs-formula{color:#8b949e}.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#7ee787}.hljs-subst{color:#c9d1d9}.hljs-section{color:#1f6feb;font-weight:700}.hljs-bullet{color:#f2cc60}.hljs-emphasis{color:#c9d1d9;font-style:italic}.hljs-strong{color:#c9d1d9;font-weight:700}.hljs-addition{color:#aff5b4;background-color:#033a16}.hljs-deletion{color:#ffdcd7;background-color:#67060c}
    	pre{-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;font-weight:400;word-break:break-word;word-wrap:break-word;box-sizing:inherit;border-radius:4px;overflow-x:auto;font-family:source-code-pro,Menlo,Monaco,"Courier New",Courier,monospace}code{-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;word-wrap:break-word;word-break:break-word;font-style:normal;line-height:20px;letter-spacing:-.003em;box-sizing:inherit;font-weight:400;font-size:75%;font-family:source-code-pro,Menlo,Monaco,"Courier New",Courier,monospace}
    </style>
    <style type="text/css">
    	.back-to-top{position:fixed;bottom:20px;right:20px;background-color:#a73f3f;color:#fff;padding:8px 10px;border-radius:50%;box-shadow:0 4px 6px rgb(0 0 0 / .2);font-size:10px;font-weight:700;text-decoration:none;text-align:center;transition:opacity 0.3s ease,visibility 0.3s ease;z-index:99999;opacity:1;visibility:visible}.back-to-top:hover{background-color:#0056b3}
    </style>
    <style type="text/css">
        .ad-header {margin: 1rem auto 1rem;background-color: #fdfdfd;text-align: center;display: block;}.ad-header .ad-wrapper {min-height: 90px;display: flex;align-items: center;justify-content: center;font-size: 1rem;color: #555;font-weight: 500;padding: 3rem;border: 1px dashed #ccc;border-radius: 6px;}@media (max-width: 768px) {.ad-header {padding: 0.75rem;}}.ad-sidebar {margin: 0 0 1rem;background-color: #fefefe;text-align: center;padding: 0px;width: 100%;max-width: 100%;display: block;}.ad-sidebar .ad-wrapper {min-height: 250px;display: flex;align-items: center;justify-content: center;font-size: 1rem;color: #444;font-weight: 500;border: 1px dashed #aaa;border-radius: 6px;padding: 0rem;}@media (max-width: 1024px) {.ad-sidebar {padding: 0.75rem;}}
    </style>
    <script type="application/ld+json">
        {
          "@context": "https://schema.org",
          "@type": "Article",
          "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://catatansoal.github.io/blog/mlp-vs-lightgbm-which-model"
          },
          "headline": "MLP Vs LightGBM: Which Model Wins For Classification?",
          "description": "MLP Vs LightGBM: Which Model Wins For Classification?...",
          "image": [
            "https://tse4.mm.bing.net/th?q=MLP%20vs%20LightGBM%3A%20A%20Deep%20Dive%20Comparison"
          ],
          "author": {
            "@type": "Person",
            "name": "ADMIN",
            "jobTitle": "Editor web"
          },
          "publisher": {
            "@type": "Organization",
            "name": "Question Notes",
            "logo": {
              "@type": "ImageObject",
              "url": "https://tse4.mm.bing.net/th?q=Question%20Notes"
            }
          },
          "datePublished": "2025-08-12T14:42:46+00:00",
          "dateModified": "2025-08-12T14:42:46+00:00"
        }
    </script>
</head>
<body>
    <header class="header">
        <nav class="nav">
            <div class="container nav-container">
                <div class="nav-left">
                    <span class="logo">Question Notes</span>
                    <span class="blog-tag">Article</span>
                </div>
                <div class="nav-search">
                    <form class="search-form" role="search">
                        <input 
                            type="search" 
                            class="search-input"
                            placeholder="Search articles..."
                            aria-label="Search articles"
                        >
                        <button type="submit" class="search-button" aria-label="Submit search">ðŸ”Ž</button>
                    </form>
                </div>
                <button class="nav-toggle" aria-label="Toggle navigation">
                    <span class="hamburger"></span>
                </button>
                <div class="nav-menu">
                    <ul class="nav-list">
                    	<li><a href="/" class="nav-link">HOME</a></li>
                        <li><a href="/pages/About" class="nav-link">About</a></li>
                        <li><a href="/pages/Contact" class="nav-link">Contact</a></li>
                        <li><a href="/pages/Disclaimer" class="nav-link">Disclaimer</a></li>
                        <li><a href="/pages/Privacy" class="nav-link">Privacy</a></li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <main class="main">
        <article class="article">
            <header class="article-header">
                <div class="container">
                    <h1>MLP Vs LightGBM: Which Model Wins For Classification?</h1>
                    <div class="meta">
                        <time datetime="2025-08-12T14:42:46+00:00">Aug 12, 2025</time>
                        <span class="author">by ADMIN</span>
                        <span class="view-count">
                            <span id="viewCount">54</span> views
                        </span>
                    </div>
                </div>
            </header>
            <div class="ad-header container">
                <!-- <div class="ad-wrapper">
    Iklan Headers
</div> -->
            </div>
            <div class="container">
                <div class="article-layout">
                    <div class="content">
                        <img src="https://tse4.mm.bing.net/th?q=MLP%20vs%20LightGBM%3A%20A%20Deep%20Dive%20Comparison" title="MLP vs LightGBM: A Deep Dive Comparison" width="300" height="200"/><p>Hey guys! Let's dive into a super interesting comparison today: <strong>MLP (Multilayer Perceptron) versus LightGBM</strong> for classification tasks. We've got a scenario where someone built an MLP from scratch, tackled a classification problem, and achieved a solid 80% accuracy with a decent confusion matrix. The data is balanced, and the model seems to be recognizing patterns well. But the question is, how does this homemade neural network stack up against the mighty LightGBM? Let's break it down!</p>
<h2>Understanding Multilayer Perceptrons (MLPs)</h2>
<p>First, let's chat about <strong>Multilayer Perceptrons (MLPs)</strong>. MLPs are a class of feedforward artificial neural networks. Think of them as the basic building blocks for more complex neural networks. They consist of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node, or neuron, in a layer is connected to every other node in the subsequent layer. The connections have weights associated with them, and these weights are what the network learns during training. When data flows through the network, each neuron applies a mathematical function (an activation function) to the weighted sum of its inputs, and then passes the result to the next layer. This process continues until the output layer produces a prediction.</p>
<p>The beauty of <strong>MLPs</strong> lies in their ability to learn complex, non-linear relationships within data. The hidden layers act as feature extractors, transforming the input data into a representation that the output layer can use to make accurate predictions. The more hidden layers and neurons you have, the more complex the patterns the network can potentially learn. However, this also means more parameters to tune, and a greater risk of overfitting, where the model learns the training data too well and performs poorly on unseen data. Building an MLP from scratch is a fantastic learning experience. It allows you to truly understand the inner workings of neural networks, from forward propagation to backpropagation, and how gradient descent optimizes the weights. You get to grapple with activation functions, loss functions, and the nuances of network architecture. But, building from scratch also means you're responsible for every detail, which can be time-consuming and require careful debugging.</p>
<p>When you're building an <strong>MLP</strong> from scratch, there are several key considerations. First, the architecture: how many layers and neurons per layer? This often involves experimentation, as there's no one-size-fits-all answer. You'll also need to choose an appropriate activation function for each layer. Common choices include ReLU (Rectified Linear Unit) for hidden layers and sigmoid or softmax for the output layer in classification tasks. Then thereâ€™s the loss function, which measures the difference between the networkâ€™s predictions and the actual values. For classification, cross-entropy loss is often used. And finally, the optimizer, which determines how the networkâ€™s weights are updated during training. Algorithms like stochastic gradient descent (SGD), Adam, and RMSprop are popular choices.</p>
<p>One of the big challenges with MLPs, especially deep ones, is the vanishing gradient problem. As gradients are backpropagated through the network, they can become very small, making it difficult for earlier layers to learn. Techniques like using ReLU activation and batch normalization can help mitigate this issue. Also, careful initialization of the weights is crucial to avoid getting stuck in local minima during training. Building and training an MLP is an iterative process. You'll likely need to adjust the architecture, learning rate, batch size, and other hyperparameters to achieve optimal performance. Validation sets are essential for monitoring performance on unseen data and preventing overfitting. Techniques like dropout and regularization can also help improve generalization. All of these things are crucial in creating an efficient and high-performance network. It is not always necessary to build a neural network from scratch, but doing so can have several great advantages. You will gain a deeper understanding of machine learning models, as well as the ability to customize your model as needed.</p>
<h2>Exploring the Power of LightGBM</h2>
<p>Now, let's shift gears and talk about <strong>LightGBM (Light Gradient Boosting Machine)</strong>. LightGBM is a gradient boosting framework developed by Microsoft. Gradient boosting is a powerful machine learning technique that builds an ensemble of decision trees sequentially. Each tree is trained to correct the errors made by the previous trees, effectively boosting the model's performance iteratively. LightGBM is specifically designed for speed and efficiency, making it a popular choice for large datasets and high-dimensional feature spaces. Its key innovations include Gradient-based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB), which reduce the computational cost without sacrificing accuracy.</p>
<p><strong>LightGBM</strong>'s GOSS technique samples the data instances for each tree based on their gradients. Instances with larger gradients, which contribute more to the error, are more likely to be selected. This allows LightGBM to focus on the most informative instances, speeding up training. EFB bundles mutually exclusive features (features that rarely take non-zero values simultaneously) into a single feature, reducing the feature space dimensionality. This is particularly effective for sparse datasets. Compared to traditional decision tree algorithms, LightGBM uses a leaf-wise (best-first) tree growth strategy rather than a level-wise strategy. Leaf-wise growth means that at each split, LightGBM chooses the leaf with the largest loss change to grow, which can lead to faster convergence and better accuracy. However, it also increases the risk of overfitting, so careful tuning is essential.</p>
<p>One of the main advantages of <strong>LightGBM</strong> is its ability to handle large datasets and high-dimensional feature spaces efficiently. Its GOSS and EFB techniques significantly reduce the computational burden, making it faster than many other gradient boosting frameworks. LightGBM also has built-in support for categorical features, which means you don't need to one-hot encode them, further improving efficiency. However, LightGBM can be more sensitive to overfitting, especially with complex datasets. Careful hyperparameter tuning is crucial to achieve optimal performance. Key hyperparameters to tune include the number of trees (n_estimators), the learning rate (learning_rate), the maximum tree depth (max_depth), the minimum number of samples per leaf (min_child_samples), and regularization parameters (reg_alpha, reg_lambda). Cross-validation is essential for evaluating model performance and preventing overfitting.</p>
<p>The leaf-wise tree growth strategy, while powerful, can lead to imbalanced trees if not controlled properly. Limiting the maximum depth of the trees and increasing the minimum number of samples per leaf can help prevent overfitting. Regularization techniques, such as L1 and L2 regularization, can also be used to penalize complex models. LightGBM is a powerful tool for many machine learning tasks, but it's not a silver bullet. Understanding its strengths and limitations, and tuning it appropriately for your specific data and problem, is key to success. Gradient boosting models like LightGBM are so powerful and useful in machine learning because they can take advantage of the information in your dataset. By iteratively building trees and focusing on the errors made by previous trees, this will create a strong and accurate predictive model. So, if you're tackling a complex classification or regression problem, LightGBM is definitely worth considering!</p>
<h2>MLP vs. LightGBM: A Head-to-Head Comparison</h2>
<p>Okay, so we've got a good grasp of both <strong>MLPs and LightGBM</strong>. Now, let's get to the juicy part: how do they stack up against each other? In the original scenario, our user achieved 80% accuracy with an MLP built from scratch. That's a solid result, but how would LightGBM fare on the same dataset? There's no one-size-fits-all answer, as the best model depends heavily on the specific data and problem. However, we can outline some general considerations.</p>
<p><strong>Performance:</strong> LightGBM often excels in tabular datasets with structured features. Its gradient boosting approach, combined with techniques like GOSS and EFB, makes it incredibly efficient and accurate. It can handle large datasets and high-dimensional feature spaces with ease. MLPs, on the other hand, can be more flexible and are particularly well-suited for unstructured data like images and text, or problems where non-linear relationships are crucial. However, they can require more data and computational resources to train effectively, and careful architecture design and hyperparameter tuning are critical.</p>
<p><strong>Training Time:</strong> This is where <strong>LightGBM</strong> often shines. Its optimized algorithms and data sampling techniques can significantly reduce training time compared to MLPs, especially for large datasets. Training an MLP, especially a deep one, can be computationally expensive and time-consuming. You'll need to experiment with different architectures, optimizers, and learning rates, which can add to the training time.</p>
<p><strong>Interpretability:</strong> LightGBM offers relatively good interpretability. You can examine the learned trees and feature importances to understand which features are most influential in the model's predictions. This can be valuable for gaining insights into the data and the problem. MLPs, in contrast, are often considered</p>

                    </div>
                    <aside class="related-posts">
                        <div class="ad-sidebar container">
                            <!-- <div class="ad-wrapper">
    <span>Iklan Related</span>
</div> -->
                        </div>
                        <h2 class="related-posts-title">Related Posts</h2><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/diy-newton-disc-exploring-light">DIY Newton Disc: Exploring Light &amp; Color Science</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-04T21:21:55+00:00">Aug 4, 2025</time>
		                        <span class="view-count">
									48 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/injured-wild-bird-care-a">Injured Wild Bird Care: A Step-by-Step Guide</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-05T06:55:58+00:00">Aug 5, 2025</time>
		                        <span class="view-count">
									44 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/troubleshoot-network-issues-on-15">Troubleshoot Network Issues On 15 PCs</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-03T02:37:31+00:00">Aug 3, 2025</time>
		                        <span class="view-count">
									37 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/intelligent-paging-efficient-data-retrieval">Intelligent Paging: Efficient Data Retrieval Guide</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-04T00:29:00+00:00">Aug 4, 2025</time>
		                        <span class="view-count">
									50 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/dye-brown-hair-black-your">Dye Brown Hair Black: Your Ultimate Step-by-Step Guide</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-01T14:18:06+00:00">Aug 1, 2025</time>
		                        <span class="view-count">
									54 views
		                        </span>
                            </div>
                        </article>
                    </aside>
                    <aside class="related-posts"></aside>
                </div>
            </div>
        </article>
        <a href="#" class="back-to-top" id="backToTop" title="Back to top">
        	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-chevron-bar-up" viewBox="0 0 16 16">
			  <path fill-rule="evenodd" d="M3.646 11.854a.5.5 0 0 0 .708 0L8 8.207l3.646 3.647a.5.5 0 0 0 .708-.708l-4-4a.5.5 0 0 0-.708 0l-4 4a.5.5 0 0 0 0 .708M2.4 5.2c0 .22.18.4.4.4h10.4a.4.4 0 0 0 0-.8H2.8a.4.4 0 0 0-.4.4"/>
			</svg>
		</a>
    </main>
    <footer class="footer">
        <div class="container">
            <p>Â© 2025 Question Notes</p>
        </div>
    </footer>
    <script>
    	(() => {
            const navToggle = document.querySelector('.nav-toggle');
            const navMenu = document.querySelector('.nav-menu');
            const toggleMenu = () => {
                navMenu.classList.toggle('nav-menu-active');
                navToggle.classList.toggle('nav-toggle-active');
            };
            const backToTopHandler = (e) => {
                e.preventDefault();
                window.scrollTo({ top: 0, behavior: 'smooth' });
            };
            navToggle.addEventListener('click', toggleMenu);
            document.getElementById('backToTop').addEventListener('click', backToTopHandler);
            window.addEventListener('pagehide', () => {
                navToggle.removeEventListener('click', toggleMenu);
                document.getElementById('backToTop').removeEventListener('click', backToTopHandler);
            });
        })();
		(() => {
            window.addEventListener("DOMContentLoaded", (event) => {
                const ellHljs = document.createElement("script");
                ellHljs.setAttribute("src", "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js");
                ellHljs.onload = () => {
                    hljs.highlightAll();
                };
                document.querySelector("body").append(ellHljs);
                const ellFont = document.createElement("link");
                ellFont.setAttribute("href", "https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css");
                ellFont.setAttribute("rel", "stylesheet");
                document.querySelector("head").append(ellFont);
                window.addEventListener('pagehide', () => {
                    // ellHljs.remove();
                    ellFont.remove();
                });

            });
        })();
    </script>
    <!-- Histats.com  START  (aync)-->
<script type="text/javascript">var _Hasync= _Hasync|| [];
_Hasync.push(['Histats.start', '1,4957095,4,0,0,0,00010000']);
_Hasync.push(['Histats.fasi', '1']);
_Hasync.push(['Histats.track_hits', '']);
(function() {
var hs = document.createElement('script'); hs.type = 'text/javascript'; hs.async = true;
hs.src = ('//s10.histats.com/js15_as.js');
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(hs);
})();</script>
<!-- Histats.com  END  -->
    
    
</body>
</html>
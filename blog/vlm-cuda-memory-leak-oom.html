<!DOCTYPE html>
<html lang="en">
<head>
	<title>VLM CUDA Memory Leak: OOM Bug Report</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="VLM CUDA Memory Leak: OOM Bug Report...">
    <link rel="canonical" href="https://catatansoal.github.io/blog/vlm-cuda-memory-leak-oom">
	<meta property="og:type" content="article">
	<meta property="og:title" content="VLM CUDA Memory Leak: OOM Bug Report">
	<meta property="og:description" content="VLM CUDA Memory Leak: OOM Bug Report...">
	<meta property="og:url" content="https://catatansoal.github.io/blog/vlm-cuda-memory-leak-oom">
	<meta property="og:site_name" content="ANABEL">
	<meta property="article:published_time" content="2025-08-07T09:06:30+00:00">
	<meta property="article:author" content="ADMIN">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    <link rel="preload" as="script" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js">
    <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
    <link rel="preload" fetchpriority="high" as="image" href="https://tse4.mm.bing.net/th?q=Bug%20Report%3A%20VLM%20CUDA%20Memory%20Leak%20Incurring%20OOM">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <style type="text/css">
    	:root{--primary-color:#3740ff;--text-color:#202124;--background-color:#ffffff;--gray-100:#f8f9fa;--gray-200:#e9ecef}*{margin:0;padding:0;box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;line-height:1.6;color:var(--text-color);background-color:var(--background-color)}.container{max-width:1200px;margin:0 auto;padding:0 1.5rem}.header{background-color:var(--background-color);border-bottom:1px solid var(--gray-200);position:sticky;top:0;z-index:100}.nav{padding:.5rem 0}.nav-container{display:flex;justify-content:space-between;align-items:center;gap:1rem}.nav-left{display:flex;align-items:center;flex-shrink:0}.logo{font-weight:700;color:var(--primary-color)}.blog-tag{margin-left:1rem;padding:.25rem .5rem;background-color:var(--gray-100);border-radius:4px;font-size:.875rem}.nav-search{flex-grow:1;max-width:300px}.search-form{position:relative;width:100%}.search-input{width:100%;padding:.5rem 2.5rem .5rem 1rem;border:1px solid var(--gray-200);border-radius:24px;font-size:.875rem;transition:all 0.2s}.search-input:focus{outline:none;border-color:var(--primary-color);box-shadow:0 0 0 2px rgb(55 64 255 / .1)}.search-button{position:absolute;right:.5rem;top:50%;transform:translateY(-50%);background:none;border:none;color:#5f6368;cursor:pointer;padding:.25rem;display:flex;align-items:center;justify-content:center}.search-button:hover{color:var(--primary-color)}.nav-toggle{display:none;background:none;border:none;cursor:pointer;padding:.5rem}.hamburger{display:block;position:relative;width:24px;height:2px;background:var(--text-color);transition:all 0.3s}.hamburger::before,.hamburger::after{content:'';position:absolute;width:24px;height:2px;background:var(--text-color);transition:all 0.3s}.hamburger::before{top:-6px}.hamburger::after{bottom:-6px}.nav-toggle-active .hamburger{background:#fff0}.nav-toggle-active .hamburger::before{transform:rotate(45deg);top:0}.nav-toggle-active .hamburger::after{transform:rotate(-45deg);bottom:0}.nav-list{display:flex;list-style:none;gap:2rem}.nav-link{color:var(--text-color);text-decoration:none;font-size:.9rem;transition:color 0.2s}.nav-link:hover{color:var(--primary-color)}.article-header{padding:2rem 0;background-color:var(--gray-100)}.article-layout{display:grid;grid-template-columns:1fr 350px;gap:3rem;padding:1rem 0;align-items: start}h1,h2,h3,h4,h5,h6{font-family:"Crimson Text","Times New Roman",Times,serif}h1{font-size:2.5rem;line-height:1.2;margin-bottom:1rem}.meta{color:#5f6368;font-size:.875rem;display:flex;align-items:center;gap:1rem;flex-wrap:wrap}.view-count{display:inline-flex;align-items:center;gap:.25rem}.view-count svg{color:#5f6368}.content{min-width:0;border-bottom:1px solid #dddddd5e;margin-top:1rem;white-space:pre-line !important;overflow-wrap:break-word;overflow-x:auto;word-break:break-word}.lead{font-size:1.25rem;color:#5f6368;margin-bottom:2rem}h2,h3,h4,h5,h6{font-size:1.75rem;margin:1rem 0 1rem}p,pre,ol,ul>li{margin-bottom:1rem;font-family:"Newsreader",serif;font-optical-sizing:auto;font-style:normal;font-size:1.3rem;text-align: justify;}p>code{font-size:1rem;font-weight:700;padding:.1rem .3rem .1rem .3rem;background:#0000000f;color:#000;border-radius:5px}hr{margin:1rem 0 1rem 0}.code-example{background-color:var(--gray-100);padding:1.5rem;border-radius:8px;margin:1.5rem 0;overflow-x:auto}code{font-family:'Roboto Mono',monospace;font-size:.875rem}ul{margin:.2rem 0;padding-left:1.5rem}.related-posts{background-color:var(--gray-100);padding:1.5rem;border-radius:8px;position:sticky;top:5rem}.related-posts-title,.newpost-posts-list{font-size:1.75rem;margin:0 0 1rem}.related-posts-list{display:flex;flex-direction:column;gap:.5rem}.related-post,.newpost-post{border-bottom:1px solid #ddd;padding-bottom:10px;margin-bottom:10px}.related-post:last-child,.newpost-post:last-child{padding-bottom:0;border-bottom:none}.related-post-title,.newpost-post-title{font-size:1.2rem;margin:0 0 .1rem;font-family:"Newsreader",serif;font-optical-sizing:auto;font-style:normal;display: -webkit-box;-webkit-line-clamp: 3;-webkit-box-orient: vertical;overflow: hidden;}.related-post-title a,.newpost-post-title a{color:var(--text-color);text-decoration:none;transition:color 0.2s}.related-post-title a:hover,.newpost-post-title a:hover{color:var(--primary-color)}.related-post time{font-size:.875rem;color:#5f6368}.footer{background-color:var(--gray-100);padding:2rem 0;margin-top:4rem;color:#5f6368;font-size:.875rem}.nav-menu>ul>li{margin-bottom:0}@media (max-width:1024px){.container{max-width:800px}.article-layout{grid-template-columns:1fr;gap:2rem}.related-posts{position:static}}@media (max-width:768px){.nav-container{flex-wrap:wrap}.nav-search{order:3;max-width:none;width:100%;margin-top:.1rem}.nav-toggle{display:block}.nav-menu{display:none;position:absolute;top:100%;left:0;right:0;background:var(--background-color);padding:1rem 0;border-bottom:1px solid var(--gray-200)}.nav-menu-active{display:block}.nav-list{flex-direction:column;gap:.1rem;padding:0 1.5rem}.nav-link{display:block;padding:.2rem 0}h1{font-size:2rem}.article-header{padding:2rem 0}.content{padding:.1rem 0}}table{width:100%;border-collapse:collapse;margin:20px 0;font-family:'Arial',sans-serif}th,td{padding:12px 15px;text-align:left;border:1px solid #ddd}th{background-color:#0F7F0B;color:#FFF}td{background-color:#f9f9f9}tr:nth-child(even) td{background-color:#f2f2f2}@media screen and (max-width:768px){table{border:0;display:block;overflow-x:auto;white-space:nowrap}th,td{padding:10px;text-align:right}th{background-color:#0F7F0B;color:#FFF}td{background-color:#f9f9f9;border-bottom:1px solid #ddd}tr:nth-child(even) td{background-color:#f2f2f2}}a{text-decoration:none;color:#540707}.katex-html{padding: .2rem;color: #000;font-weight: 700;font-size: 1.3rem;overflow-wrap: break-word;max-width: 100%;white-space: normal !important}.category{display:flex;align-items:center;gap:.5rem;flex-wrap:wrap;margin:1rem 0 1rem 0}.tag{font-size:1rem;font-weight:700;padding:.1rem .3rem .1rem .3rem;background:#0000000f;color:#000;border-radius:5px;font-family:"Newsreader",serif}.tag>a{text-decoration:none;color:#000}img{margin:auto;display:block;max-width:100%;height:auto;margin-bottom:1rem}.katex{white-space: pre-line !important;display: inline-block;max-width: 100%;overflow-x: auto;overflow-y: hidden;scrollbar-width: thin;overflow-wrap: break-word;word-break: break-word;vertical-align: -7px}.content > p {overflow-wrap: break-word;word-break: break-word}
    </style>
    <style type="text/css">
    	pre code.hljs{display:block;overflow-x:auto;padding:1em}code.hljs{padding:3px 5px}
		.hljs{color:#c9d1d9;background:#0d1117}.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#ff7b72}.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#d2a8ff}.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#79c0ff}.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#a5d6ff}.hljs-built_in,.hljs-symbol{color:#ffa657}.hljs-code,.hljs-comment,.hljs-formula{color:#8b949e}.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#7ee787}.hljs-subst{color:#c9d1d9}.hljs-section{color:#1f6feb;font-weight:700}.hljs-bullet{color:#f2cc60}.hljs-emphasis{color:#c9d1d9;font-style:italic}.hljs-strong{color:#c9d1d9;font-weight:700}.hljs-addition{color:#aff5b4;background-color:#033a16}.hljs-deletion{color:#ffdcd7;background-color:#67060c}
    	pre{-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;font-weight:400;word-break:break-word;word-wrap:break-word;box-sizing:inherit;border-radius:4px;overflow-x:auto;font-family:source-code-pro,Menlo,Monaco,"Courier New",Courier,monospace}code{-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;word-wrap:break-word;word-break:break-word;font-style:normal;line-height:20px;letter-spacing:-.003em;box-sizing:inherit;font-weight:400;font-size:75%;font-family:source-code-pro,Menlo,Monaco,"Courier New",Courier,monospace}
    </style>
    <style type="text/css">
    	.back-to-top{position:fixed;bottom:20px;right:20px;background-color:#a73f3f;color:#fff;padding:8px 10px;border-radius:50%;box-shadow:0 4px 6px rgb(0 0 0 / .2);font-size:10px;font-weight:700;text-decoration:none;text-align:center;transition:opacity 0.3s ease,visibility 0.3s ease;z-index:99999;opacity:1;visibility:visible}.back-to-top:hover{background-color:#0056b3}
    </style>
    <style type="text/css">
        .ad-header {margin: 1rem auto 1rem;background-color: #fdfdfd;text-align: center;display: block;}.ad-header .ad-wrapper {min-height: 90px;display: flex;align-items: center;justify-content: center;font-size: 1rem;color: #555;font-weight: 500;padding: 3rem;border: 1px dashed #ccc;border-radius: 6px;}@media (max-width: 768px) {.ad-header {padding: 0.75rem;}}.ad-sidebar {margin: 0 0 1rem;background-color: #fefefe;text-align: center;padding: 0px;width: 100%;max-width: 100%;display: block;}.ad-sidebar .ad-wrapper {min-height: 250px;display: flex;align-items: center;justify-content: center;font-size: 1rem;color: #444;font-weight: 500;border: 1px dashed #aaa;border-radius: 6px;padding: 0rem;}@media (max-width: 1024px) {.ad-sidebar {padding: 0.75rem;}}
    </style>
    <script type="application/ld+json">
        {
          "@context": "https://schema.org",
          "@type": "Article",
          "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://catatansoal.github.io/blog/vlm-cuda-memory-leak-oom"
          },
          "headline": "VLM CUDA Memory Leak: OOM Bug Report",
          "description": "VLM CUDA Memory Leak: OOM Bug Report...",
          "image": [
            "https://tse4.mm.bing.net/th?q=Bug%20Report%3A%20VLM%20CUDA%20Memory%20Leak%20Incurring%20OOM"
          ],
          "author": {
            "@type": "Person",
            "name": "ADMIN",
            "jobTitle": "Editor web"
          },
          "publisher": {
            "@type": "Organization",
            "name": "ANABEL",
            "logo": {
              "@type": "ImageObject",
              "url": "https://tse4.mm.bing.net/th?q=ANABEL%20WEB"
            }
          },
          "datePublished": "2025-08-07T09:06:30+00:00",
          "dateModified": "2025-08-07T09:06:30+00:00"
        }
    </script>
</head>
<body>
    <header class="header">
        <nav class="nav">
            <div class="container nav-container">
                <div class="nav-left">
                    <span class="logo">ANABEL</span>
                    <span class="blog-tag">Article</span>
                </div>
                <div class="nav-search">
                    <form class="search-form" role="search">
                        <input 
                            type="search" 
                            class="search-input"
                            placeholder="Search articles..."
                            aria-label="Search articles"
                        >
                        <button type="submit" class="search-button" aria-label="Submit search">🔎</button>
                    </form>
                </div>
                <button class="nav-toggle" aria-label="Toggle navigation">
                    <span class="hamburger"></span>
                </button>
                <div class="nav-menu">
                    <ul class="nav-list">
                    	<li><a href="/" class="nav-link">HOME</a></li>
                        <li><a href="/pages/About" class="nav-link">About</a></li>
                        <li><a href="/pages/Contact" class="nav-link">Contact</a></li>
                        <li><a href="/pages/Disclaimer" class="nav-link">Disclaimer</a></li>
                        <li><a href="/pages/Privacy" class="nav-link">Privacy</a></li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <main class="main">
        <article class="article">
            <header class="article-header">
                <div class="container">
                    <h1>VLM CUDA Memory Leak: OOM Bug Report</h1>
                    <div class="meta">
                        <time datetime="2025-08-07T09:06:30+00:00">Aug 7, 2025</time>
                        <span class="author">by ADMIN</span>
                        <span class="view-count">
                            <span id="viewCount">37</span> views
                        </span>
                    </div>
                </div>
            </header>
            <div class="ad-header container">
                <div class="ad-wrapper">
    Iklan Headers
</div>
            </div>
            <div class="container">
                <div class="article-layout">
                    <div class="content">
                        <img src="https://tse4.mm.bing.net/th?q=Bug%20Report%3A%20VLM%20CUDA%20Memory%20Leak%20Incurring%20OOM" title="Bug Report: VLM CUDA Memory Leak Incurring OOM" width="300" height="200"/><h2>Introduction</h2>
<p>Hey everyone, I've encountered a rather significant issue while serving Visual Language Models (VLMs) like Qwen2.5-VL-3B, 7B, and 32B. It appears there's a CUDA memory leak that eventually leads to an out-of-memory (OOM) error. This is a critical problem as it severely impacts the usability and reliability of the service. I want to share my findings, the steps to reproduce the bug, and my system environment in detail so we can squash this bug together!</p>
<h3>The Problem</h3>
<p>When serving VLMs, the GPU memory usage steadily increases with each request. This incremental memory consumption continues until the GPU runs out of memory, causing the service to crash. This memory leak makes it impossible to run the service reliably for an extended period, as the server grinds to a halt after processing a limited number of requests.</p>
<h3>Why This Matters</h3>
<p>This memory leak isn't just a minor inconvenience; it's a major roadblock for anyone looking to deploy VLMs in a production environment. Imagine trying to build a real-time image captioning service or a visual question-answering system, only to have it crash every few minutes because of memory issues. This bug undermines the practicality of these models and significantly limits their potential applications.</p>
<h3>Steps to Reproduce</h3>
<p>To reproduce this issue, follow the steps below. These steps outline how to set up the server and run a client script that triggers the memory leak. By following these instructions, you should be able to observe the memory consumption increase and, eventually, the OOM error. Let's get into the nitty-gritty details so you can see the issue firsthand.</p>
<h4>1. Start the Server</h4>
<p>First, you'll need to start the VLM server using the provided command. This command specifies the model, tensor parallelism, number of nodes, node rank, and other necessary configurations. Make sure you have the correct model path and that all dependencies are installed.</p>
<pre><code class="hljs">python -m sglang.launch_server --model-path Qwen2.5-VL-3B-Instruct --tp 1 --nnodes 1 --node-rank 0 --trust-remote-code --host 0.0.0.0 --port 30000
</code></pre>
<p>This command does the following:</p>
<ul>
<li><code>python -m sglang.launch_server</code>: This initiates the SGLang server.</li>
<li><code>--model-path Qwen2.5-VL-3B-Instruct</code>: Specifies the path to the Qwen2.5-VL-3B-Instruct model. Make sure this path is correct and accessible.</li>
<li><code>--tp 1</code>: Sets tensor parallelism to 1, meaning the model is not split across multiple GPUs in this case.</li>
<li><code>--nnodes 1</code>: Indicates that the service is running on a single node.</li>
<li><code>--node-rank 0</code>: Sets the rank of the node to 0, which is typical for a single-node setup.</li>
<li><code>--trust-remote-code</code>: Allows the execution of remote code, which is necessary for some models.</li>
<li><code>--host 0.0.0.0</code>: Binds the server to all available network interfaces.</li>
<li><code>--port 30000</code>: Sets the port number to 30000.</li>
</ul>
<h4>2. Run the Client Code</h4>
<p>Next, you'll execute the client code that sends requests to the server. This Python script uses the OpenAI API to interact with the VLM server. The script sends a series of requests, each including an image URL and a text prompt, to simulate real-world usage.</p>
<pre><code class="hljs">import openai


client = openai.Client(api_key=&quot;EMPTY&quot;, base_url=&quot;http://127.0.0.1:30000/v1&quot;)
model_name = client.models.list().data[0].id

sampling_params = {&quot;max_tokens&quot;: 512, &quot;temperature&quot;: 0}

url = &quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png&quot;
messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;please describe this image&quot;},
            {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: url}},
        ]
    }
]

for idx in range(100):
    print(f&quot;{idx} req&quot;)
    response = client.chat.completions.create(
        model=model_name,
        messages=messages,
        **sampling_params,
    )
    # time.sleep(0.5)

print(response)
</code></pre>
<p>Let's break down what this code does:</p>
<ul>
<li><code>import openai</code>: Imports the OpenAI library, which is used to interact with the VLM server.</li>
<li><code>client = openai.Client(api_key=&quot;EMPTY&quot;, base_url=&quot;http://127.0.0.1:30000/v1&quot;)</code>: Creates an OpenAI client instance, specifying the base URL of the server. The <code>api_key</code> is set to &quot;EMPTY&quot; as it's not required for local testing.</li>
<li><code>model_name = client.models.list().data[0].id</code>: Retrieves the model name from the server. This assumes that the server has at least one model loaded.</li>
<li><code>sampling_params = {&quot;max_tokens&quot;: 512, &quot;temperature&quot;: 0}</code>: Defines the sampling parameters for the model. <code>max_tokens</code> limits the response length, and <code>temperature</code> controls the randomness of the output.</li>
<li><code>url = &quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png&quot;</code>: Specifies the URL of the image to be processed.</li>
<li><code>messages = [...]</code>: Constructs the message payload for the API request. This includes a system message defining the assistant's role and a user message containing both text and an image URL.</li>
<li><code>for idx in range(100):</code>: Sends 100 requests to the server in a loop.</li>
<li><code>response = client.chat.completions.create(...)</code>: Sends a chat completion request to the server, including the model name, messages, and sampling parameters.</li>
<li><code>print(response)</code>: Prints the final response from the server.</li>
</ul>
<h4>3. Observe Memory Consumption</h4>
<p>As the client script runs, monitor the GPU memory usage. You should observe that the memory consumption increases with each request. After a few requests (typically between 2 and 5), you'll likely see a memory occupation bump of about 20 MB. This incremental increase continues until the GPU runs out of memory and the process crashes. Tools like <code>nvidia-smi</code> can be invaluable for tracking GPU memory usage in real-time.</p>
<h3>Expected Result</h3>
<p>The expected result is that the GPU memory usage will continuously increase until an out-of-memory error occurs. This behavior confirms the presence of the memory leak. By reproducing this issue, we can gather more information about the conditions that trigger the leak and work towards a solution.</p>
<h3>Actual Result</h3>
<p>In reality, every 2 to 5 requests cause a memory occupation bump of approximately 20 MB. This steady increase in memory consumption leads to the GPU eventually running out of memory, which is far from ideal.</p>
<h2>Environment Details</h2>
<p>Here’s a detailed breakdown of the environment in which this bug was observed. Understanding the environment is crucial for identifying potential conflicts or compatibility issues. Make sure your setup is similar to this one when attempting to reproduce the bug.</p>
<ul>
<li><strong>Python:</strong> 3.10.12 (main, May 27 2025, 17:12:29) [GCC 11.4.0]</li>
<li><strong>CUDA Available:</strong> True</li>
<li><strong>GPUs:</strong> NVIDIA A10 (4 GPUs)</li>
<li><strong>GPU Compute Capability:</strong> 8.6</li>
<li><strong>CUDA_HOME:</strong> /usr/local/cuda</li>
<li><strong>NVCC:</strong> Cuda compilation tools, release 12.6, V12.6.68</li>
<li><strong>CUDA Driver Version:</strong> 470.161.03</li>
<li><strong>PyTorch:</strong> 2.7.1+cu126</li>
<li><strong>sglang:</strong> 0.4.9.post6</li>
<li><strong>sgl_kernel:</strong> 0.2.7</li>
<li><strong>flashinfer_python:</strong> 0.2.9rc2</li>
<li><strong>triton:</strong> 3.3.1</li>
<li><strong>transformers:</strong> 4.53.0</li>
<li><strong>torchao:</strong> 0.9.0+cu126</li>
<li><strong>numpy:</strong> 2.2.6</li>
<li><strong>aiohttp:</strong> 3.12.14</li>
<li><strong>fastapi:</strong> 0.116.1</li>
<li><strong>hf_transfer:</strong> 0.1.9</li>
<li><strong>huggingface_hub:</strong> 0.34.3</li>
<li><strong>interegular:</strong> 0.3.3</li>
<li><strong>modelscope:</strong> 1.28.0</li>
<li><strong>orjson:</strong> 3.10.18</li>
<li><strong>outlines:</strong> 0.1.11</li>
<li><strong>packaging:</strong> 25.0</li>
<li><strong>psutil:</strong> 7.0.0</li>
<li><strong>pydantic:</strong> 2.11.7</li>
<li><strong>python-multipart:</strong> 0.0.20</li>
<li><strong>pyzmq:</strong> 27.0.0</li>
<li><strong>uvicorn:</strong> 0.35.0</li>
<li><strong>uvloop:</strong> 0.21.0</li>
<li><strong>vllm:</strong> 0.9.0.1</li>
<li><strong>xgrammar:</strong> 0.1.21</li>
<li><strong>openai:</strong> 1.95.1</li>
<li><strong>tiktoken:</strong> 0.9.0</li>
<li><strong>anthropic:</strong> 0.57.1</li>
<li><strong>litellm:</strong> 1.74.2</li>
<li><strong>decord:</strong> 0.6.0</li>
</ul>
<h4>NVIDIA Topology</h4>
<p>Understanding the GPU topology can also be helpful. Here’s the NVIDIA topology information:</p>
<pre><code class="hljs">NVIDIA Topology: 
	GPU0	GPU1	GPU2	GPU3	mlx5_0	CPU Affinity	NUMA Affinity
GPU0	 X 	PHB	SYS	SYS	SYS	0-117	0
GPU1	PHB	 X 	SYS	SYS	SYS	0-117	0
GPU2	SYS	SYS	 X 	PHB	SYS	118-235	1
GPU3	SYS	SYS	PHB	 X 	SYS	118-235	1
mx5_0	SYS	SYS	SYS	SYS	 X 		

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
</code></pre>
<h4>Hypervisor Vendor</h4>
<ul>
<li><strong>Hypervisor vendor:</strong> KVM</li>
</ul>
<h2>Additional Information</h2>
<p>Before submitting this bug report, I made sure to go through a checklist to ensure I've covered all the bases. Let's quickly run through that checklist to confirm everything’s in order.</p>
<h3>Checklist</h3>
<ul>
<li>[x] 1. I have searched related issues but cannot get the expected help. I've scoured the existing issues to see if anyone else has reported a similar problem. Unfortunately, I couldn't find a solution that addresses this specific memory leak.</li>
<li>[x] 2. The bug has not been fixed in the latest version. I've made sure that I'm running the latest version of the software to rule out the possibility that this bug has already been addressed in a recent update. Sadly, the issue persists.</li>
<li>[x] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback. I've provided detailed environment information and a minimal reproducible demo to make it as easy as possible for the developers to understand and fix this bug.</li>
<li>[ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at <a href="https://github.com/sgl-project/sglang/discussions/new/choose">https://github.com/sgl-project/sglang/discussions/new/choose</a> Otherwise, it will be closed. I'm confident that this is a bug and not a question, so I'm submitting it as a bug report.</li>
<li>[x] 5. Please use English, otherwise, it will be closed. This report is written in English to ensure it’s accessible to the broadest possible audience.</li>
</ul>
<h2>Conclusion</h2>
<p>This <strong>VLM CUDA memory leak</strong> is a critical issue that needs to be addressed to ensure the reliable deployment of these models. I've provided a detailed report with steps to reproduce the bug and comprehensive environment information. Hopefully, this will help in identifying and resolving the issue quickly. Let's work together to get this fixed, guys, so we can fully utilize the potential of these amazing models!</p>

                    </div>
                    <aside class="related-posts">
                        <div class="ad-sidebar container">
                            <div class="ad-wrapper">
    <span>Iklan Related</span>
</div>
                        </div>
                        <h2 class="related-posts-title">Related Posts</h2><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/web3-js-frontend-integration-guide">Web3.js Frontend Integration Guide For Voting DApps</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-05T16:37:53+00:00">Aug 5, 2025</time>
		                        <span class="view-count">
									51 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/strong-force-unlocking-secrets-of">Strong Force: Unlocking Secrets Of The Nucleus</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-06T15:26:48+00:00">Aug 6, 2025</time>
		                        <span class="view-count">
									46 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/master-the-pull-up-technique">Master The Pull-Up: Technique, Muscles &amp; Training</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-03T18:40:23+00:00">Aug 3, 2025</time>
		                        <span class="view-count">
									49 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/cyanide-guaranteed-keycard-drops-explained">Cyanide: Guaranteed Keycard Drops Explained</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-09T13:56:05+00:00">Aug 9, 2025</time>
		                        <span class="view-count">
									43 views
		                        </span>
                            </div>
                        </article><article class="related-post">
                            <h3 class="related-post-title">
                                <a href="https://catatansoal.github.io/blog/unclaimed-entities-plugin-simplify-backstage">Unclaimed Entities Plugin: Simplify Backstage Adoption</a>
                            </h3>
                            <div class="meta">
                            	<time datetime="2025-08-02T21:59:01+00:00">Aug 2, 2025</time>
		                        <span class="view-count">
									54 views
		                        </span>
                            </div>
                        </article>
                    </aside>
                    <aside class="related-posts"></aside>
                </div>
            </div>
        </article>
        <a href="#" class="back-to-top" id="backToTop" title="Back to top">
        	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-chevron-bar-up" viewBox="0 0 16 16">
			  <path fill-rule="evenodd" d="M3.646 11.854a.5.5 0 0 0 .708 0L8 8.207l3.646 3.647a.5.5 0 0 0 .708-.708l-4-4a.5.5 0 0 0-.708 0l-4 4a.5.5 0 0 0 0 .708M2.4 5.2c0 .22.18.4.4.4h10.4a.4.4 0 0 0 0-.8H2.8a.4.4 0 0 0-.4.4"/>
			</svg>
		</a>
    </main>
    <footer class="footer">
        <div class="container">
            <p>© 2025 ANABEL</p>
        </div>
    </footer>
    <script>
    	(() => {
            const navToggle = document.querySelector('.nav-toggle');
            const navMenu = document.querySelector('.nav-menu');
            const toggleMenu = () => {
                navMenu.classList.toggle('nav-menu-active');
                navToggle.classList.toggle('nav-toggle-active');
            };
            const backToTopHandler = (e) => {
                e.preventDefault();
                window.scrollTo({ top: 0, behavior: 'smooth' });
            };
            navToggle.addEventListener('click', toggleMenu);
            document.getElementById('backToTop').addEventListener('click', backToTopHandler);
            window.addEventListener('pagehide', () => {
                navToggle.removeEventListener('click', toggleMenu);
                document.getElementById('backToTop').removeEventListener('click', backToTopHandler);
            });
        })();
		(() => {
            window.addEventListener("DOMContentLoaded", (event) => {
                const ellHljs = document.createElement("script");
                ellHljs.setAttribute("src", "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js");
                ellHljs.onload = () => {
                    hljs.highlightAll();
                };
                document.querySelector("body").append(ellHljs);
                const ellFont = document.createElement("link");
                ellFont.setAttribute("href", "https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css");
                ellFont.setAttribute("rel", "stylesheet");
                document.querySelector("head").append(ellFont);
                window.addEventListener('pagehide', () => {
                    // ellHljs.remove();
                    ellFont.remove();
                });

            });
        })();
    </script>
    
    
    
</body>
</html>